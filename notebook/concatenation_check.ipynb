{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sachi\\Documents\\Researchcode\\research\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\sachi\\Documents\\Researchcode\\research\\lib\\site-packages\\backtesting\\_plotting.py:55: UserWarning: Jupyter Notebook detected. Setting Bokeh output to notebook. This may not work in Jupyter clients without JavaScript support, such as old IDEs. Reset with `backtesting.set_bokeh_output(notebook=False)`.\n",
      "  warnings.warn('Jupyter Notebook detected. '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "    <style>\n",
       "        .bk-notebook-logo {\n",
       "            display: block;\n",
       "            width: 20px;\n",
       "            height: 20px;\n",
       "            background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAABx0RVh0U29mdHdhcmUAQWRvYmUgRmlyZXdvcmtzIENTNui8sowAAAOkSURBVDiNjZRtaJVlGMd/1/08zzln5zjP1LWcU9N0NkN8m2CYjpgQYQXqSs0I84OLIC0hkEKoPtiH3gmKoiJDU7QpLgoLjLIQCpEsNJ1vqUOdO7ppbuec5+V+rj4ctwzd8IIbbi6u+8f1539dt3A78eXC7QizUF7gyV1fD1Yqg4JWz84yffhm0qkFqBogB9rM8tZdtwVsPUhWhGcFJngGeWrPzHm5oaMmkfEg1usvLFyc8jLRqDOMru7AyC8saQr7GG7f5fvDeH7Ej8CM66nIF+8yngt6HWaKh7k49Soy9nXurCi1o3qUbS3zWfrYeQDTB/Qj6kX6Ybhw4B+bOYoLKCC9H3Nu/leUTZ1JdRWkkn2ldcCamzrcf47KKXdAJllSlxAOkRgyHsGC/zRday5Qld9DyoM4/q/rUoy/CXh3jzOu3bHUVZeU+DEn8FInkPBFlu3+nW3Nw0mk6vCDiWg8CeJaxEwuHS3+z5RgY+YBR6V1Z1nxSOfoaPa4LASWxxdNp+VWTk7+4vzaou8v8PN+xo+KY2xsw6une2frhw05CTYOmQvsEhjhWjn0bmXPjpE1+kplmmkP3suftwTubK9Vq22qKmrBhpY4jvd5afdRA3wGjFAgcnTK2s4hY0/GPNIb0nErGMCRxWOOX64Z8RAC4oCXdklmEvcL8o0BfkNK4lUg9HTl+oPlQxdNo3Mg4Nv175e/1LDGzZen30MEjRUtmXSfiTVu1kK8W4txyV6BMKlbgk3lMwYCiusNy9fVfvvwMxv8Ynl6vxoByANLTWplvuj/nF9m2+PDtt1eiHPBr1oIfhCChQMBw6Aw0UulqTKZdfVvfG7VcfIqLG9bcldL/+pdWTLxLUy8Qq38heUIjh4XlzZxzQm19lLFlr8vdQ97rjZVOLf8nclzckbcD4wxXMidpX30sFd37Fv/GtwwhzhxGVAprjbg0gCAEeIgwCZyTV2Z1REEW8O4py0wsjeloKoMr6iCY6dP92H6Vw/oTyICIthibxjm/DfN9lVz8IqtqKYLUXfoKVMVQVVJOElGjrnnUt9T9wbgp8AyYKaGlqingHZU/uG2NTZSVqwHQTWkx9hxjkpWDaCg6Ckj5qebgBVbT3V3NNXMSiWSDdGV3hrtzla7J+duwPOToIg42ChPQOQjspnSlp1V+Gjdged7+8UN5CRAV7a5EdFNwCjEaBR27b3W890TE7g24NAP/mMDXRWrGoFPQI9ls/MWO2dWFAar/xcOIImbbpA3zgAAAABJRU5ErkJggg==);\n",
       "        }\n",
       "    </style>\n",
       "    <div>\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-notebook-logo\"></a>\n",
       "        <span id=\"e2bae457-2483-43b0-9590-eaa76defa98b\">Loading BokehJS ...</span>\n",
       "    </div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "'use strict';\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\nconst JS_MIME_TYPE = 'application/javascript';\n  const HTML_MIME_TYPE = 'text/html';\n  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n  const CLASS_NAME = 'output_bokeh rendered_html';\n\n  /**\n   * Render data to the DOM node\n   */\n  function render(props, node) {\n    const script = document.createElement(\"script\");\n    node.appendChild(script);\n  }\n\n  /**\n   * Handle when an output is cleared or removed\n   */\n  function handleClearOutput(event, handle) {\n    function drop(id) {\n      const view = Bokeh.index.get_by_id(id)\n      if (view != null) {\n        view.model.document.clear()\n        Bokeh.index.delete(view)\n      }\n    }\n\n    const cell = handle.cell;\n\n    const id = cell.output_area._bokeh_element_id;\n    const server_id = cell.output_area._bokeh_server_id;\n\n    // Clean up Bokeh references\n    if (id != null) {\n      drop(id)\n    }\n\n    if (server_id !== undefined) {\n      // Clean up Bokeh references\n      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n      cell.notebook.kernel.execute(cmd_clean, {\n        iopub: {\n          output: function(msg) {\n            const id = msg.content.text.trim()\n            drop(id)\n          }\n        }\n      });\n      // Destroy server and session\n      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n      cell.notebook.kernel.execute(cmd_destroy);\n    }\n  }\n\n  /**\n   * Handle when a new output is added\n   */\n  function handleAddOutput(event, handle) {\n    const output_area = handle.output_area;\n    const output = handle.output;\n\n    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n      return\n    }\n\n    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n\n    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n      // store reference to embed id on output_area\n      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n    }\n    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n      const bk_div = document.createElement(\"div\");\n      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n      const script_attrs = bk_div.children[0].attributes;\n      for (let i = 0; i < script_attrs.length; i++) {\n        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n      }\n      // store reference to server id on output_area\n      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n    }\n  }\n\n  function register_renderer(events, OutputArea) {\n\n    function append_mime(data, metadata, element) {\n      // create a DOM node to render to\n      const toinsert = this.create_output_subarea(\n        metadata,\n        CLASS_NAME,\n        EXEC_MIME_TYPE\n      );\n      this.keyboard_manager.register_events(toinsert);\n      // Render to node\n      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n      render(props, toinsert[toinsert.length - 1]);\n      element.append(toinsert);\n      return toinsert\n    }\n\n    /* Handle when an output is cleared or removed */\n    events.on('clear_output.CodeCell', handleClearOutput);\n    events.on('delete.Cell', handleClearOutput);\n\n    /* Handle when a new output is added */\n    events.on('output_added.OutputArea', handleAddOutput);\n\n    /**\n     * Register the mime type and append_mime function with output_area\n     */\n    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n      /* Is output safe? */\n      safe: true,\n      /* Index of renderer in `output_area.display_order` */\n      index: 0\n    });\n  }\n\n  // register the mime type if in Jupyter Notebook environment and previously unregistered\n  if (root.Jupyter !== undefined) {\n    const events = require('base/js/events');\n    const OutputArea = require('notebook/js/outputarea').OutputArea;\n\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  }\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded(error = null) {\n    const el = document.getElementById(\"e2bae457-2483-43b0-9590-eaa76defa98b\");\n    if (el != null) {\n      const html = (() => {\n        if (typeof root.Bokeh === \"undefined\") {\n          if (error == null) {\n            return \"BokehJS is loading ...\";\n          } else {\n            return \"BokehJS failed to load.\";\n          }\n        } else {\n          const prefix = `BokehJS ${root.Bokeh.version}`;\n          if (error == null) {\n            return `${prefix} successfully loaded.`;\n          } else {\n            return `${prefix} <b>encountered errors</b> while loading and may not function as expected.`;\n          }\n        }\n      })();\n      el.innerHTML = html;\n\n      if (error != null) {\n        const wrapper = document.createElement(\"div\");\n        wrapper.style.overflow = \"auto\";\n        wrapper.style.height = \"5em\";\n        wrapper.style.resize = \"vertical\";\n        const content = document.createElement(\"div\");\n        content.style.fontFamily = \"monospace\";\n        content.style.whiteSpace = \"pre-wrap\";\n        content.style.backgroundColor = \"rgb(255, 221, 221)\";\n        content.textContent = error.stack ?? error.toString();\n        wrapper.append(content);\n        el.append(wrapper);\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(() => display_loaded(error), 100);\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.7.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.7.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.7.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.7.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.7.0.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n      try {\n            for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n\n      } catch (error) {display_loaded(error);throw error;\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"e2bae457-2483-43b0-9590-eaa76defa98b\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));",
      "application/vnd.bokehjs_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from main import run,normal_run\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on merged_data_AAPL_from_2015-01-01_to_2025-03-01.csv\n",
      "Loading Data for AAPL, testing on number of lag 5, saving path is strategy_5\n",
      "\n",
      "Logistic Regression Performance:\n",
      "Accuracy: 0.8596\n",
      "Confusion Matrix:\n",
      "[[270  91]\n",
      " [ 15 379]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.75      0.84       361\n",
      "           1       0.81      0.96      0.88       394\n",
      "\n",
      "    accuracy                           0.86       755\n",
      "   macro avg       0.88      0.85      0.86       755\n",
      "weighted avg       0.87      0.86      0.86       755\n",
      "\n",
      "\n",
      "Random Forest Performance:\n",
      "Accuracy: 0.8411\n",
      "Confusion Matrix:\n",
      "[[261 100]\n",
      " [ 20 374]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.72      0.81       361\n",
      "           1       0.79      0.95      0.86       394\n",
      "\n",
      "    accuracy                           0.84       755\n",
      "   macro avg       0.86      0.84      0.84       755\n",
      "weighted avg       0.86      0.84      0.84       755\n",
      "\n",
      "\n",
      "XGBoost Performance:\n",
      "Accuracy: 0.8821\n",
      "Confusion Matrix:\n",
      "[[301  60]\n",
      " [ 29 365]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.83      0.87       361\n",
      "           1       0.86      0.93      0.89       394\n",
      "\n",
      "    accuracy                           0.88       755\n",
      "   macro avg       0.89      0.88      0.88       755\n",
      "weighted avg       0.88      0.88      0.88       755\n",
      "\n",
      "\n",
      "SVM Performance:\n",
      "Accuracy: 0.8623\n",
      "Confusion Matrix:\n",
      "[[277  84]\n",
      " [ 20 374]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.77      0.84       361\n",
      "           1       0.82      0.95      0.88       394\n",
      "\n",
      "    accuracy                           0.86       755\n",
      "   macro avg       0.87      0.86      0.86       755\n",
      "weighted avg       0.87      0.86      0.86       755\n",
      "\n",
      "\n",
      "Naive Bayes Performance:\n",
      "Accuracy: 0.8675\n",
      "Confusion Matrix:\n",
      "[[277  84]\n",
      " [ 16 378]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.77      0.85       361\n",
      "           1       0.82      0.96      0.88       394\n",
      "\n",
      "    accuracy                           0.87       755\n",
      "   macro avg       0.88      0.86      0.87       755\n",
      "weighted avg       0.88      0.87      0.87       755\n",
      "\n",
      "\n",
      "Gradient Boosting Performance:\n",
      "Accuracy: 0.8834\n",
      "Confusion Matrix:\n",
      "[[308  53]\n",
      " [ 35 359]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.85      0.88       361\n",
      "           1       0.87      0.91      0.89       394\n",
      "\n",
      "    accuracy                           0.88       755\n",
      "   macro avg       0.88      0.88      0.88       755\n",
      "weighted avg       0.88      0.88      0.88       755\n",
      "\n",
      "\n",
      "K-Nearest Neighbors Performance:\n",
      "Accuracy: 0.8358\n",
      "Confusion Matrix:\n",
      "[[248 113]\n",
      " [ 11 383]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.69      0.80       361\n",
      "           1       0.77      0.97      0.86       394\n",
      "\n",
      "    accuracy                           0.84       755\n",
      "   macro avg       0.86      0.83      0.83       755\n",
      "weighted avg       0.86      0.84      0.83       755\n",
      "\n",
      "\n",
      "Decision Tree Performance:\n",
      "Accuracy: 0.8358\n",
      "Confusion Matrix:\n",
      "[[290  71]\n",
      " [ 53 341]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.80      0.82       361\n",
      "           1       0.83      0.87      0.85       394\n",
      "\n",
      "    accuracy                           0.84       755\n",
      "   macro avg       0.84      0.83      0.84       755\n",
      "weighted avg       0.84      0.84      0.84       755\n",
      "\n",
      "\n",
      "AdaBoost Performance:\n",
      "Accuracy: 0.8834\n",
      "Confusion Matrix:\n",
      "[[306  55]\n",
      " [ 33 361]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.85      0.87       361\n",
      "           1       0.87      0.92      0.89       394\n",
      "\n",
      "    accuracy                           0.88       755\n",
      "   macro avg       0.89      0.88      0.88       755\n",
      "weighted avg       0.88      0.88      0.88       755\n",
      "\n",
      "\n",
      "SGD Classifier Performance:\n",
      "Accuracy: 0.8662\n",
      "Confusion Matrix:\n",
      "[[275  86]\n",
      " [ 15 379]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.76      0.84       361\n",
      "           1       0.82      0.96      0.88       394\n",
      "\n",
      "    accuracy                           0.87       755\n",
      "   macro avg       0.88      0.86      0.86       755\n",
      "weighted avg       0.88      0.87      0.86       755\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sachi\\Documents\\Researchcode\\research\\lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MLP Performance:\n",
      "Accuracy: 0.8450\n",
      "Confusion Matrix:\n",
      "[[273  88]\n",
      " [ 29 365]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.76      0.82       361\n",
      "           1       0.81      0.93      0.86       394\n",
      "\n",
      "    accuracy                           0.85       755\n",
      "   macro avg       0.85      0.84      0.84       755\n",
      "weighted avg       0.85      0.85      0.84       755\n",
      "\n",
      "[LightGBM] [Info] Number of positive: 1104, number of negative: 657\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000693 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6630\n",
      "[LightGBM] [Info] Number of data points in the train set: 1761, number of used features: 26\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.626917 -> initscore=0.519011\n",
      "[LightGBM] [Info] Start training from score 0.519011\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\n",
      "LGBMClassifier Performance:\n",
      "Accuracy: 0.8980\n",
      "Confusion Matrix:\n",
      "[[303  58]\n",
      " [ 19 375]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.84      0.89       361\n",
      "           1       0.87      0.95      0.91       394\n",
      "\n",
      "    accuracy                           0.90       755\n",
      "   macro avg       0.90      0.90      0.90       755\n",
      "weighted avg       0.90      0.90      0.90       755\n",
      "\n",
      "Backtesting for Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for Random Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for XGBoost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for SVM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for Naive Bayes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for Gradient Boosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for K-Nearest Neighbors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for Decision Tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for AdaBoost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for SGD Classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for LGBMClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Backtesting Result\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal Results and Returns Saved\n",
      "Working on merged_data_AMD_from_2015-01-01_to_2025-03-01.csv\n",
      "Loading Data for AMD, testing on number of lag 5, saving path is strategy_5\n",
      "\n",
      "Logistic Regression Performance:\n",
      "Accuracy: 0.8702\n",
      "Confusion Matrix:\n",
      "[[384  39]\n",
      " [ 59 273]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.91      0.89       423\n",
      "           1       0.88      0.82      0.85       332\n",
      "\n",
      "    accuracy                           0.87       755\n",
      "   macro avg       0.87      0.87      0.87       755\n",
      "weighted avg       0.87      0.87      0.87       755\n",
      "\n",
      "\n",
      "Random Forest Performance:\n",
      "Accuracy: 0.8106\n",
      "Confusion Matrix:\n",
      "[[369  54]\n",
      " [ 89 243]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.87      0.84       423\n",
      "           1       0.82      0.73      0.77       332\n",
      "\n",
      "    accuracy                           0.81       755\n",
      "   macro avg       0.81      0.80      0.81       755\n",
      "weighted avg       0.81      0.81      0.81       755\n",
      "\n",
      "\n",
      "XGBoost Performance:\n",
      "Accuracy: 0.8609\n",
      "Confusion Matrix:\n",
      "[[349  74]\n",
      " [ 31 301]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.83      0.87       423\n",
      "           1       0.80      0.91      0.85       332\n",
      "\n",
      "    accuracy                           0.86       755\n",
      "   macro avg       0.86      0.87      0.86       755\n",
      "weighted avg       0.87      0.86      0.86       755\n",
      "\n",
      "\n",
      "SVM Performance:\n",
      "Accuracy: 0.8649\n",
      "Confusion Matrix:\n",
      "[[393  30]\n",
      " [ 72 260]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.93      0.89       423\n",
      "           1       0.90      0.78      0.84       332\n",
      "\n",
      "    accuracy                           0.86       755\n",
      "   macro avg       0.87      0.86      0.86       755\n",
      "weighted avg       0.87      0.86      0.86       755\n",
      "\n",
      "\n",
      "Naive Bayes Performance:\n",
      "Accuracy: 0.8490\n",
      "Confusion Matrix:\n",
      "[[384  39]\n",
      " [ 75 257]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.91      0.87       423\n",
      "           1       0.87      0.77      0.82       332\n",
      "\n",
      "    accuracy                           0.85       755\n",
      "   macro avg       0.85      0.84      0.84       755\n",
      "weighted avg       0.85      0.85      0.85       755\n",
      "\n",
      "\n",
      "Gradient Boosting Performance:\n",
      "Accuracy: 0.8649\n",
      "Confusion Matrix:\n",
      "[[386  37]\n",
      " [ 65 267]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.91      0.88       423\n",
      "           1       0.88      0.80      0.84       332\n",
      "\n",
      "    accuracy                           0.86       755\n",
      "   macro avg       0.87      0.86      0.86       755\n",
      "weighted avg       0.87      0.86      0.86       755\n",
      "\n",
      "\n",
      "K-Nearest Neighbors Performance:\n",
      "Accuracy: 0.6914\n",
      "Confusion Matrix:\n",
      "[[309 114]\n",
      " [119 213]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.73      0.73       423\n",
      "           1       0.65      0.64      0.65       332\n",
      "\n",
      "    accuracy                           0.69       755\n",
      "   macro avg       0.69      0.69      0.69       755\n",
      "weighted avg       0.69      0.69      0.69       755\n",
      "\n",
      "\n",
      "Decision Tree Performance:\n",
      "Accuracy: 0.6556\n",
      "Confusion Matrix:\n",
      "[[334  89]\n",
      " [171 161]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.79      0.72       423\n",
      "           1       0.64      0.48      0.55       332\n",
      "\n",
      "    accuracy                           0.66       755\n",
      "   macro avg       0.65      0.64      0.64       755\n",
      "weighted avg       0.65      0.66      0.65       755\n",
      "\n",
      "\n",
      "AdaBoost Performance:\n",
      "Accuracy: 0.8570\n",
      "Confusion Matrix:\n",
      "[[380  43]\n",
      " [ 65 267]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.88       423\n",
      "           1       0.86      0.80      0.83       332\n",
      "\n",
      "    accuracy                           0.86       755\n",
      "   macro avg       0.86      0.85      0.85       755\n",
      "weighted avg       0.86      0.86      0.86       755\n",
      "\n",
      "\n",
      "SGD Classifier Performance:\n",
      "Accuracy: 0.8768\n",
      "Confusion Matrix:\n",
      "[[355  68]\n",
      " [ 25 307]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.84      0.88       423\n",
      "           1       0.82      0.92      0.87       332\n",
      "\n",
      "    accuracy                           0.88       755\n",
      "   macro avg       0.88      0.88      0.88       755\n",
      "weighted avg       0.88      0.88      0.88       755\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sachi\\Documents\\Researchcode\\research\\lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MLP Performance:\n",
      "Accuracy: 0.8556\n",
      "Confusion Matrix:\n",
      "[[367  56]\n",
      " [ 53 279]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.87      0.87       423\n",
      "           1       0.83      0.84      0.84       332\n",
      "\n",
      "    accuracy                           0.86       755\n",
      "   macro avg       0.85      0.85      0.85       755\n",
      "weighted avg       0.86      0.86      0.86       755\n",
      "\n",
      "[LightGBM] [Info] Number of positive: 1051, number of negative: 710\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000450 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6627\n",
      "[LightGBM] [Info] Number of data points in the train set: 1761, number of used features: 26\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.596820 -> initscore=0.392232\n",
      "[LightGBM] [Info] Start training from score 0.392232\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\n",
      "LGBMClassifier Performance:\n",
      "Accuracy: 0.8238\n",
      "Confusion Matrix:\n",
      "[[381  42]\n",
      " [ 91 241]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.90      0.85       423\n",
      "           1       0.85      0.73      0.78       332\n",
      "\n",
      "    accuracy                           0.82       755\n",
      "   macro avg       0.83      0.81      0.82       755\n",
      "weighted avg       0.83      0.82      0.82       755\n",
      "\n",
      "Backtesting for Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for Random Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for XGBoost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for SVM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for Naive Bayes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for Gradient Boosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for K-Nearest Neighbors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for Decision Tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for AdaBoost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for SGD Classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for LGBMClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Backtesting Result\n",
      "Normal Results and Returns Saved\n",
      "Working on merged_data_AMZN_from_2015-01-01_to_2025-03-01.csv\n",
      "Loading Data for AMZN, testing on number of lag 5, saving path is strategy_5\n",
      "\n",
      "Logistic Regression Performance:\n",
      "Accuracy: 0.8517\n",
      "Confusion Matrix:\n",
      "[[256  29]\n",
      " [ 83 387]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.90      0.82       285\n",
      "           1       0.93      0.82      0.87       470\n",
      "\n",
      "    accuracy                           0.85       755\n",
      "   macro avg       0.84      0.86      0.85       755\n",
      "weighted avg       0.86      0.85      0.85       755\n",
      "\n",
      "\n",
      "Random Forest Performance:\n",
      "Accuracy: 0.8834\n",
      "Confusion Matrix:\n",
      "[[249  36]\n",
      " [ 52 418]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.87      0.85       285\n",
      "           1       0.92      0.89      0.90       470\n",
      "\n",
      "    accuracy                           0.88       755\n",
      "   macro avg       0.87      0.88      0.88       755\n",
      "weighted avg       0.89      0.88      0.88       755\n",
      "\n",
      "\n",
      "XGBoost Performance:\n",
      "Accuracy: 0.8583\n",
      "Confusion Matrix:\n",
      "[[246  39]\n",
      " [ 68 402]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.86      0.82       285\n",
      "           1       0.91      0.86      0.88       470\n",
      "\n",
      "    accuracy                           0.86       755\n",
      "   macro avg       0.85      0.86      0.85       755\n",
      "weighted avg       0.86      0.86      0.86       755\n",
      "\n",
      "\n",
      "SVM Performance:\n",
      "Accuracy: 0.8675\n",
      "Confusion Matrix:\n",
      "[[254  31]\n",
      " [ 69 401]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.89      0.84       285\n",
      "           1       0.93      0.85      0.89       470\n",
      "\n",
      "    accuracy                           0.87       755\n",
      "   macro avg       0.86      0.87      0.86       755\n",
      "weighted avg       0.87      0.87      0.87       755\n",
      "\n",
      "\n",
      "Naive Bayes Performance:\n",
      "Accuracy: 0.8132\n",
      "Confusion Matrix:\n",
      "[[279   6]\n",
      " [135 335]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.98      0.80       285\n",
      "           1       0.98      0.71      0.83       470\n",
      "\n",
      "    accuracy                           0.81       755\n",
      "   macro avg       0.83      0.85      0.81       755\n",
      "weighted avg       0.87      0.81      0.82       755\n",
      "\n",
      "\n",
      "Gradient Boosting Performance:\n",
      "Accuracy: 0.8728\n",
      "Confusion Matrix:\n",
      "[[240  45]\n",
      " [ 51 419]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83       285\n",
      "           1       0.90      0.89      0.90       470\n",
      "\n",
      "    accuracy                           0.87       755\n",
      "   macro avg       0.86      0.87      0.87       755\n",
      "weighted avg       0.87      0.87      0.87       755\n",
      "\n",
      "\n",
      "K-Nearest Neighbors Performance:\n",
      "Accuracy: 0.8954\n",
      "Confusion Matrix:\n",
      "[[254  31]\n",
      " [ 48 422]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.89      0.87       285\n",
      "           1       0.93      0.90      0.91       470\n",
      "\n",
      "    accuracy                           0.90       755\n",
      "   macro avg       0.89      0.89      0.89       755\n",
      "weighted avg       0.90      0.90      0.90       755\n",
      "\n",
      "\n",
      "Decision Tree Performance:\n",
      "Accuracy: 0.8490\n",
      "Confusion Matrix:\n",
      "[[247  38]\n",
      " [ 76 394]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.87      0.81       285\n",
      "           1       0.91      0.84      0.87       470\n",
      "\n",
      "    accuracy                           0.85       755\n",
      "   macro avg       0.84      0.85      0.84       755\n",
      "weighted avg       0.86      0.85      0.85       755\n",
      "\n",
      "\n",
      "AdaBoost Performance:\n",
      "Accuracy: 0.8636\n",
      "Confusion Matrix:\n",
      "[[255  30]\n",
      " [ 73 397]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.89      0.83       285\n",
      "           1       0.93      0.84      0.89       470\n",
      "\n",
      "    accuracy                           0.86       755\n",
      "   macro avg       0.85      0.87      0.86       755\n",
      "weighted avg       0.87      0.86      0.87       755\n",
      "\n",
      "\n",
      "SGD Classifier Performance:\n",
      "Accuracy: 0.8689\n",
      "Confusion Matrix:\n",
      "[[263  22]\n",
      " [ 77 393]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.92      0.84       285\n",
      "           1       0.95      0.84      0.89       470\n",
      "\n",
      "    accuracy                           0.87       755\n",
      "   macro avg       0.86      0.88      0.86       755\n",
      "weighted avg       0.88      0.87      0.87       755\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sachi\\Documents\\Researchcode\\research\\lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MLP Performance:\n",
      "Accuracy: 0.8728\n",
      "Confusion Matrix:\n",
      "[[229  56]\n",
      " [ 40 430]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.80      0.83       285\n",
      "           1       0.88      0.91      0.90       470\n",
      "\n",
      "    accuracy                           0.87       755\n",
      "   macro avg       0.87      0.86      0.86       755\n",
      "weighted avg       0.87      0.87      0.87       755\n",
      "\n",
      "[LightGBM] [Info] Number of positive: 1079, number of negative: 682\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000409 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6406\n",
      "[LightGBM] [Info] Number of data points in the train set: 1761, number of used features: 26\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.612720 -> initscore=0.458760\n",
      "[LightGBM] [Info] Start training from score 0.458760\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\n",
      "LGBMClassifier Performance:\n",
      "Accuracy: 0.8861\n",
      "Confusion Matrix:\n",
      "[[246  39]\n",
      " [ 47 423]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.86      0.85       285\n",
      "           1       0.92      0.90      0.91       470\n",
      "\n",
      "    accuracy                           0.89       755\n",
      "   macro avg       0.88      0.88      0.88       755\n",
      "weighted avg       0.89      0.89      0.89       755\n",
      "\n",
      "Backtesting for Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for Random Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for XGBoost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for SVM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for Naive Bayes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for Gradient Boosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for K-Nearest Neighbors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for Decision Tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for AdaBoost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for SGD Classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for LGBMClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Backtesting Result\n",
      "Normal Results and Returns Saved\n",
      "Working on merged_data_GOOGL_from_2015-01-01_to_2025-03-01.csv\n",
      "Loading Data for GOOGL, testing on number of lag 5, saving path is strategy_5\n",
      "\n",
      "Logistic Regression Performance:\n",
      "Accuracy: 0.9205\n",
      "Confusion Matrix:\n",
      "[[293  37]\n",
      " [ 23 402]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91       330\n",
      "           1       0.92      0.95      0.93       425\n",
      "\n",
      "    accuracy                           0.92       755\n",
      "   macro avg       0.92      0.92      0.92       755\n",
      "weighted avg       0.92      0.92      0.92       755\n",
      "\n",
      "\n",
      "Random Forest Performance:\n",
      "Accuracy: 0.8517\n",
      "Confusion Matrix:\n",
      "[[253  77]\n",
      " [ 35 390]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.77      0.82       330\n",
      "           1       0.84      0.92      0.87       425\n",
      "\n",
      "    accuracy                           0.85       755\n",
      "   macro avg       0.86      0.84      0.85       755\n",
      "weighted avg       0.85      0.85      0.85       755\n",
      "\n",
      "\n",
      "XGBoost Performance:\n",
      "Accuracy: 0.9113\n",
      "Confusion Matrix:\n",
      "[[301  29]\n",
      " [ 38 387]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.91      0.90       330\n",
      "           1       0.93      0.91      0.92       425\n",
      "\n",
      "    accuracy                           0.91       755\n",
      "   macro avg       0.91      0.91      0.91       755\n",
      "weighted avg       0.91      0.91      0.91       755\n",
      "\n",
      "\n",
      "SVM Performance:\n",
      "Accuracy: 0.9232\n",
      "Confusion Matrix:\n",
      "[[297  33]\n",
      " [ 25 400]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.90      0.91       330\n",
      "           1       0.92      0.94      0.93       425\n",
      "\n",
      "    accuracy                           0.92       755\n",
      "   macro avg       0.92      0.92      0.92       755\n",
      "weighted avg       0.92      0.92      0.92       755\n",
      "\n",
      "\n",
      "Naive Bayes Performance:\n",
      "Accuracy: 0.5629\n",
      "Confusion Matrix:\n",
      "[[  0 330]\n",
      " [  0 425]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       330\n",
      "           1       0.56      1.00      0.72       425\n",
      "\n",
      "    accuracy                           0.56       755\n",
      "   macro avg       0.28      0.50      0.36       755\n",
      "weighted avg       0.32      0.56      0.41       755\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sachi\\Documents\\Researchcode\\research\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\sachi\\Documents\\Researchcode\\research\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\sachi\\Documents\\Researchcode\\research\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gradient Boosting Performance:\n",
      "Accuracy: 0.8715\n",
      "Confusion Matrix:\n",
      "[[248  82]\n",
      " [ 15 410]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.75      0.84       330\n",
      "           1       0.83      0.96      0.89       425\n",
      "\n",
      "    accuracy                           0.87       755\n",
      "   macro avg       0.89      0.86      0.87       755\n",
      "weighted avg       0.88      0.87      0.87       755\n",
      "\n",
      "\n",
      "K-Nearest Neighbors Performance:\n",
      "Accuracy: 0.8411\n",
      "Confusion Matrix:\n",
      "[[255  75]\n",
      " [ 45 380]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.77      0.81       330\n",
      "           1       0.84      0.89      0.86       425\n",
      "\n",
      "    accuracy                           0.84       755\n",
      "   macro avg       0.84      0.83      0.84       755\n",
      "weighted avg       0.84      0.84      0.84       755\n",
      "\n",
      "\n",
      "Decision Tree Performance:\n",
      "Accuracy: 0.8331\n",
      "Confusion Matrix:\n",
      "[[242  88]\n",
      " [ 38 387]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.73      0.79       330\n",
      "           1       0.81      0.91      0.86       425\n",
      "\n",
      "    accuracy                           0.83       755\n",
      "   macro avg       0.84      0.82      0.83       755\n",
      "weighted avg       0.84      0.83      0.83       755\n",
      "\n",
      "\n",
      "AdaBoost Performance:\n",
      "Accuracy: 0.8874\n",
      "Confusion Matrix:\n",
      "[[285  45]\n",
      " [ 40 385]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.86      0.87       330\n",
      "           1       0.90      0.91      0.90       425\n",
      "\n",
      "    accuracy                           0.89       755\n",
      "   macro avg       0.89      0.88      0.89       755\n",
      "weighted avg       0.89      0.89      0.89       755\n",
      "\n",
      "\n",
      "SGD Classifier Performance:\n",
      "Accuracy: 0.9126\n",
      "Confusion Matrix:\n",
      "[[313  17]\n",
      " [ 49 376]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.90       330\n",
      "           1       0.96      0.88      0.92       425\n",
      "\n",
      "    accuracy                           0.91       755\n",
      "   macro avg       0.91      0.92      0.91       755\n",
      "weighted avg       0.92      0.91      0.91       755\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sachi\\Documents\\Researchcode\\research\\lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MLP Performance:\n",
      "Accuracy: 0.8649\n",
      "Confusion Matrix:\n",
      "[[260  70]\n",
      " [ 32 393]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.79      0.84       330\n",
      "           1       0.85      0.92      0.89       425\n",
      "\n",
      "    accuracy                           0.86       755\n",
      "   macro avg       0.87      0.86      0.86       755\n",
      "weighted avg       0.87      0.86      0.86       755\n",
      "\n",
      "[LightGBM] [Info] Number of positive: 1025, number of negative: 736\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000502 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6400\n",
      "[LightGBM] [Info] Number of data points in the train set: 1761, number of used features: 26\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.582056 -> initscore=0.331218\n",
      "[LightGBM] [Info] Start training from score 0.331218\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\n",
      "LGBMClassifier Performance:\n",
      "Accuracy: 0.9073\n",
      "Confusion Matrix:\n",
      "[[277  53]\n",
      " [ 17 408]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.84      0.89       330\n",
      "           1       0.89      0.96      0.92       425\n",
      "\n",
      "    accuracy                           0.91       755\n",
      "   macro avg       0.91      0.90      0.90       755\n",
      "weighted avg       0.91      0.91      0.91       755\n",
      "\n",
      "Backtesting for Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for Random Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for XGBoost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for SVM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for Naive Bayes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for Gradient Boosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for K-Nearest Neighbors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for Decision Tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for AdaBoost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for SGD Classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for LGBMClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Backtesting Result\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal Results and Returns Saved\n",
      "Working on merged_data_META_from_2015-01-01_to_2025-03-01.csv\n",
      "Loading Data for META, testing on number of lag 5, saving path is strategy_5\n",
      "\n",
      "Logistic Regression Performance:\n",
      "Accuracy: 0.8185\n",
      "Confusion Matrix:\n",
      "[[177  75]\n",
      " [ 62 441]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.70      0.72       252\n",
      "           1       0.85      0.88      0.87       503\n",
      "\n",
      "    accuracy                           0.82       755\n",
      "   macro avg       0.80      0.79      0.79       755\n",
      "weighted avg       0.82      0.82      0.82       755\n",
      "\n",
      "\n",
      "Random Forest Performance:\n",
      "Accuracy: 0.8397\n",
      "Confusion Matrix:\n",
      "[[203  49]\n",
      " [ 72 431]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.81      0.77       252\n",
      "           1       0.90      0.86      0.88       503\n",
      "\n",
      "    accuracy                           0.84       755\n",
      "   macro avg       0.82      0.83      0.82       755\n",
      "weighted avg       0.84      0.84      0.84       755\n",
      "\n",
      "\n",
      "XGBoost Performance:\n",
      "Accuracy: 0.8371\n",
      "Confusion Matrix:\n",
      "[[186  66]\n",
      " [ 57 446]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.74      0.75       252\n",
      "           1       0.87      0.89      0.88       503\n",
      "\n",
      "    accuracy                           0.84       755\n",
      "   macro avg       0.82      0.81      0.82       755\n",
      "weighted avg       0.84      0.84      0.84       755\n",
      "\n",
      "\n",
      "SVM Performance:\n",
      "Accuracy: 0.8146\n",
      "Confusion Matrix:\n",
      "[[174  78]\n",
      " [ 62 441]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.69      0.71       252\n",
      "           1       0.85      0.88      0.86       503\n",
      "\n",
      "    accuracy                           0.81       755\n",
      "   macro avg       0.79      0.78      0.79       755\n",
      "weighted avg       0.81      0.81      0.81       755\n",
      "\n",
      "\n",
      "Naive Bayes Performance:\n",
      "Accuracy: 0.8371\n",
      "Confusion Matrix:\n",
      "[[199  53]\n",
      " [ 70 433]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.79      0.76       252\n",
      "           1       0.89      0.86      0.88       503\n",
      "\n",
      "    accuracy                           0.84       755\n",
      "   macro avg       0.82      0.83      0.82       755\n",
      "weighted avg       0.84      0.84      0.84       755\n",
      "\n",
      "\n",
      "Gradient Boosting Performance:\n",
      "Accuracy: 0.8093\n",
      "Confusion Matrix:\n",
      "[[207  45]\n",
      " [ 99 404]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.82      0.74       252\n",
      "           1       0.90      0.80      0.85       503\n",
      "\n",
      "    accuracy                           0.81       755\n",
      "   macro avg       0.79      0.81      0.80       755\n",
      "weighted avg       0.83      0.81      0.81       755\n",
      "\n",
      "\n",
      "K-Nearest Neighbors Performance:\n",
      "Accuracy: 0.7669\n",
      "Confusion Matrix:\n",
      "[[193  59]\n",
      " [117 386]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.77      0.69       252\n",
      "           1       0.87      0.77      0.81       503\n",
      "\n",
      "    accuracy                           0.77       755\n",
      "   macro avg       0.74      0.77      0.75       755\n",
      "weighted avg       0.79      0.77      0.77       755\n",
      "\n",
      "\n",
      "Decision Tree Performance:\n",
      "Accuracy: 0.8344\n",
      "Confusion Matrix:\n",
      "[[201  51]\n",
      " [ 74 429]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.80      0.76       252\n",
      "           1       0.89      0.85      0.87       503\n",
      "\n",
      "    accuracy                           0.83       755\n",
      "   macro avg       0.81      0.83      0.82       755\n",
      "weighted avg       0.84      0.83      0.84       755\n",
      "\n",
      "\n",
      "AdaBoost Performance:\n",
      "Accuracy: 0.8464\n",
      "Confusion Matrix:\n",
      "[[196  56]\n",
      " [ 60 443]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.78      0.77       252\n",
      "           1       0.89      0.88      0.88       503\n",
      "\n",
      "    accuracy                           0.85       755\n",
      "   macro avg       0.83      0.83      0.83       755\n",
      "weighted avg       0.85      0.85      0.85       755\n",
      "\n",
      "\n",
      "SGD Classifier Performance:\n",
      "Accuracy: 0.8305\n",
      "Confusion Matrix:\n",
      "[[214  38]\n",
      " [ 90 413]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.85      0.77       252\n",
      "           1       0.92      0.82      0.87       503\n",
      "\n",
      "    accuracy                           0.83       755\n",
      "   macro avg       0.81      0.84      0.82       755\n",
      "weighted avg       0.85      0.83      0.83       755\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sachi\\Documents\\Researchcode\\research\\lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MLP Performance:\n",
      "Accuracy: 0.7907\n",
      "Confusion Matrix:\n",
      "[[161  91]\n",
      " [ 67 436]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.64      0.67       252\n",
      "           1       0.83      0.87      0.85       503\n",
      "\n",
      "    accuracy                           0.79       755\n",
      "   macro avg       0.77      0.75      0.76       755\n",
      "weighted avg       0.79      0.79      0.79       755\n",
      "\n",
      "[LightGBM] [Info] Number of positive: 1092, number of negative: 669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000559 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6375\n",
      "[LightGBM] [Info] Number of data points in the train set: 1761, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.620102 -> initscore=0.489982\n",
      "[LightGBM] [Info] Start training from score 0.489982\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\n",
      "LGBMClassifier Performance:\n",
      "Accuracy: 0.8278\n",
      "Confusion Matrix:\n",
      "[[193  59]\n",
      " [ 71 432]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.77      0.75       252\n",
      "           1       0.88      0.86      0.87       503\n",
      "\n",
      "    accuracy                           0.83       755\n",
      "   macro avg       0.81      0.81      0.81       755\n",
      "weighted avg       0.83      0.83      0.83       755\n",
      "\n",
      "Backtesting for Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for Random Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for XGBoost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for SVM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for Naive Bayes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for Gradient Boosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for K-Nearest Neighbors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for Decision Tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for AdaBoost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for SGD Classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for LGBMClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Backtesting Result\n",
      "Normal Results and Returns Saved\n",
      "Working on merged_data_MSFT_from_2015-01-01_to_2025-03-01.csv\n",
      "Loading Data for MSFT, testing on number of lag 5, saving path is strategy_5\n",
      "\n",
      "Logistic Regression Performance:\n",
      "Accuracy: 0.8967\n",
      "Confusion Matrix:\n",
      "[[327  12]\n",
      " [ 66 350]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89       339\n",
      "           1       0.97      0.84      0.90       416\n",
      "\n",
      "    accuracy                           0.90       755\n",
      "   macro avg       0.90      0.90      0.90       755\n",
      "weighted avg       0.91      0.90      0.90       755\n",
      "\n",
      "\n",
      "Random Forest Performance:\n",
      "Accuracy: 0.6384\n",
      "Confusion Matrix:\n",
      "[[336   3]\n",
      " [270 146]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.99      0.71       339\n",
      "           1       0.98      0.35      0.52       416\n",
      "\n",
      "    accuracy                           0.64       755\n",
      "   macro avg       0.77      0.67      0.61       755\n",
      "weighted avg       0.79      0.64      0.60       755\n",
      "\n",
      "\n",
      "XGBoost Performance:\n",
      "Accuracy: 0.9086\n",
      "Confusion Matrix:\n",
      "[[315  24]\n",
      " [ 45 371]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.90       339\n",
      "           1       0.94      0.89      0.91       416\n",
      "\n",
      "    accuracy                           0.91       755\n",
      "   macro avg       0.91      0.91      0.91       755\n",
      "weighted avg       0.91      0.91      0.91       755\n",
      "\n",
      "\n",
      "SVM Performance:\n",
      "Accuracy: 0.8940\n",
      "Confusion Matrix:\n",
      "[[325  14]\n",
      " [ 66 350]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89       339\n",
      "           1       0.96      0.84      0.90       416\n",
      "\n",
      "    accuracy                           0.89       755\n",
      "   macro avg       0.90      0.90      0.89       755\n",
      "weighted avg       0.90      0.89      0.89       755\n",
      "\n",
      "\n",
      "Naive Bayes Performance:\n",
      "Accuracy: 0.8609\n",
      "Confusion Matrix:\n",
      "[[310  29]\n",
      " [ 76 340]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.91      0.86       339\n",
      "           1       0.92      0.82      0.87       416\n",
      "\n",
      "    accuracy                           0.86       755\n",
      "   macro avg       0.86      0.87      0.86       755\n",
      "weighted avg       0.87      0.86      0.86       755\n",
      "\n",
      "\n",
      "Gradient Boosting Performance:\n",
      "Accuracy: 0.8013\n",
      "Confusion Matrix:\n",
      "[[335   4]\n",
      " [146 270]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.99      0.82       339\n",
      "           1       0.99      0.65      0.78       416\n",
      "\n",
      "    accuracy                           0.80       755\n",
      "   macro avg       0.84      0.82      0.80       755\n",
      "weighted avg       0.86      0.80      0.80       755\n",
      "\n",
      "\n",
      "K-Nearest Neighbors Performance:\n",
      "Accuracy: 0.7470\n",
      "Confusion Matrix:\n",
      "[[329  10]\n",
      " [181 235]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.97      0.78       339\n",
      "           1       0.96      0.56      0.71       416\n",
      "\n",
      "    accuracy                           0.75       755\n",
      "   macro avg       0.80      0.77      0.74       755\n",
      "weighted avg       0.82      0.75      0.74       755\n",
      "\n",
      "\n",
      "Decision Tree Performance:\n",
      "Accuracy: 0.7377\n",
      "Confusion Matrix:\n",
      "[[318  21]\n",
      " [177 239]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.94      0.76       339\n",
      "           1       0.92      0.57      0.71       416\n",
      "\n",
      "    accuracy                           0.74       755\n",
      "   macro avg       0.78      0.76      0.73       755\n",
      "weighted avg       0.79      0.74      0.73       755\n",
      "\n",
      "\n",
      "AdaBoost Performance:\n",
      "Accuracy: 0.8861\n",
      "Confusion Matrix:\n",
      "[[330   9]\n",
      " [ 77 339]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.97      0.88       339\n",
      "           1       0.97      0.81      0.89       416\n",
      "\n",
      "    accuracy                           0.89       755\n",
      "   macro avg       0.89      0.89      0.89       755\n",
      "weighted avg       0.90      0.89      0.89       755\n",
      "\n",
      "\n",
      "SGD Classifier Performance:\n",
      "Accuracy: 0.9060\n",
      "Confusion Matrix:\n",
      "[[325  14]\n",
      " [ 57 359]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.96      0.90       339\n",
      "           1       0.96      0.86      0.91       416\n",
      "\n",
      "    accuracy                           0.91       755\n",
      "   macro avg       0.91      0.91      0.91       755\n",
      "weighted avg       0.91      0.91      0.91       755\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sachi\\Documents\\Researchcode\\research\\lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MLP Performance:\n",
      "Accuracy: 0.8662\n",
      "Confusion Matrix:\n",
      "[[324  15]\n",
      " [ 86 330]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.96      0.87       339\n",
      "           1       0.96      0.79      0.87       416\n",
      "\n",
      "    accuracy                           0.87       755\n",
      "   macro avg       0.87      0.87      0.87       755\n",
      "weighted avg       0.88      0.87      0.87       755\n",
      "\n",
      "[LightGBM] [Info] Number of positive: 1117, number of negative: 644\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000495 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6398\n",
      "[LightGBM] [Info] Number of data points in the train set: 1761, number of used features: 26\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.634299 -> initscore=0.550703\n",
      "[LightGBM] [Info] Start training from score 0.550703\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\n",
      "LGBMClassifier Performance:\n",
      "Accuracy: 0.7695\n",
      "Confusion Matrix:\n",
      "[[332   7]\n",
      " [167 249]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.98      0.79       339\n",
      "           1       0.97      0.60      0.74       416\n",
      "\n",
      "    accuracy                           0.77       755\n",
      "   macro avg       0.82      0.79      0.77       755\n",
      "weighted avg       0.83      0.77      0.76       755\n",
      "\n",
      "Backtesting for Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for Random Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for XGBoost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for SVM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for Naive Bayes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for Gradient Boosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for K-Nearest Neighbors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for Decision Tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for AdaBoost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for SGD Classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for LGBMClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Backtesting Result\n",
      "Normal Results and Returns Saved\n",
      "Working on merged_data_NFLX_from_2015-01-01_to_2025-03-01.csv\n",
      "Loading Data for NFLX, testing on number of lag 5, saving path is strategy_5\n",
      "\n",
      "Logistic Regression Performance:\n",
      "Accuracy: 0.8543\n",
      "Confusion Matrix:\n",
      "[[227  23]\n",
      " [ 87 418]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.91      0.80       250\n",
      "           1       0.95      0.83      0.88       505\n",
      "\n",
      "    accuracy                           0.85       755\n",
      "   macro avg       0.84      0.87      0.84       755\n",
      "weighted avg       0.87      0.85      0.86       755\n",
      "\n",
      "\n",
      "Random Forest Performance:\n",
      "Accuracy: 0.8424\n",
      "Confusion Matrix:\n",
      "[[198  52]\n",
      " [ 67 438]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.79      0.77       250\n",
      "           1       0.89      0.87      0.88       505\n",
      "\n",
      "    accuracy                           0.84       755\n",
      "   macro avg       0.82      0.83      0.82       755\n",
      "weighted avg       0.85      0.84      0.84       755\n",
      "\n",
      "\n",
      "XGBoost Performance:\n",
      "Accuracy: 0.8384\n",
      "Confusion Matrix:\n",
      "[[177  73]\n",
      " [ 49 456]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.71      0.74       250\n",
      "           1       0.86      0.90      0.88       505\n",
      "\n",
      "    accuracy                           0.84       755\n",
      "   macro avg       0.82      0.81      0.81       755\n",
      "weighted avg       0.84      0.84      0.84       755\n",
      "\n",
      "\n",
      "SVM Performance:\n",
      "Accuracy: 0.8583\n",
      "Confusion Matrix:\n",
      "[[224  26]\n",
      " [ 81 424]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.90      0.81       250\n",
      "           1       0.94      0.84      0.89       505\n",
      "\n",
      "    accuracy                           0.86       755\n",
      "   macro avg       0.84      0.87      0.85       755\n",
      "weighted avg       0.87      0.86      0.86       755\n",
      "\n",
      "\n",
      "Naive Bayes Performance:\n",
      "Accuracy: 0.8742\n",
      "Confusion Matrix:\n",
      "[[222  28]\n",
      " [ 67 438]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.89      0.82       250\n",
      "           1       0.94      0.87      0.90       505\n",
      "\n",
      "    accuracy                           0.87       755\n",
      "   macro avg       0.85      0.88      0.86       755\n",
      "weighted avg       0.88      0.87      0.88       755\n",
      "\n",
      "\n",
      "Gradient Boosting Performance:\n",
      "Accuracy: 0.8397\n",
      "Confusion Matrix:\n",
      "[[195  55]\n",
      " [ 66 439]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.78      0.76       250\n",
      "           1       0.89      0.87      0.88       505\n",
      "\n",
      "    accuracy                           0.84       755\n",
      "   macro avg       0.82      0.82      0.82       755\n",
      "weighted avg       0.84      0.84      0.84       755\n",
      "\n",
      "\n",
      "K-Nearest Neighbors Performance:\n",
      "Accuracy: 0.8358\n",
      "Confusion Matrix:\n",
      "[[178  72]\n",
      " [ 52 453]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.71      0.74       250\n",
      "           1       0.86      0.90      0.88       505\n",
      "\n",
      "    accuracy                           0.84       755\n",
      "   macro avg       0.82      0.80      0.81       755\n",
      "weighted avg       0.83      0.84      0.83       755\n",
      "\n",
      "\n",
      "Decision Tree Performance:\n",
      "Accuracy: 0.8477\n",
      "Confusion Matrix:\n",
      "[[204  46]\n",
      " [ 69 436]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.78       250\n",
      "           1       0.90      0.86      0.88       505\n",
      "\n",
      "    accuracy                           0.85       755\n",
      "   macro avg       0.83      0.84      0.83       755\n",
      "weighted avg       0.85      0.85      0.85       755\n",
      "\n",
      "\n",
      "AdaBoost Performance:\n",
      "Accuracy: 0.8543\n",
      "Confusion Matrix:\n",
      "[[215  35]\n",
      " [ 75 430]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.86      0.80       250\n",
      "           1       0.92      0.85      0.89       505\n",
      "\n",
      "    accuracy                           0.85       755\n",
      "   macro avg       0.83      0.86      0.84       755\n",
      "weighted avg       0.86      0.85      0.86       755\n",
      "\n",
      "\n",
      "SGD Classifier Performance:\n",
      "Accuracy: 0.8861\n",
      "Confusion Matrix:\n",
      "[[224  26]\n",
      " [ 60 445]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.90      0.84       250\n",
      "           1       0.94      0.88      0.91       505\n",
      "\n",
      "    accuracy                           0.89       755\n",
      "   macro avg       0.87      0.89      0.88       755\n",
      "weighted avg       0.89      0.89      0.89       755\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sachi\\Documents\\Researchcode\\research\\lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MLP Performance:\n",
      "Accuracy: 0.8464\n",
      "Confusion Matrix:\n",
      "[[212  38]\n",
      " [ 78 427]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.85      0.79       250\n",
      "           1       0.92      0.85      0.88       505\n",
      "\n",
      "    accuracy                           0.85       755\n",
      "   macro avg       0.82      0.85      0.83       755\n",
      "weighted avg       0.86      0.85      0.85       755\n",
      "\n",
      "[LightGBM] [Info] Number of positive: 1038, number of negative: 723\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000497 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6402\n",
      "[LightGBM] [Info] Number of data points in the train set: 1761, number of used features: 26\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.589438 -> initscore=0.361642\n",
      "[LightGBM] [Info] Start training from score 0.361642\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\n",
      "LGBMClassifier Performance:\n",
      "Accuracy: 0.8411\n",
      "Confusion Matrix:\n",
      "[[185  65]\n",
      " [ 55 450]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.74      0.76       250\n",
      "           1       0.87      0.89      0.88       505\n",
      "\n",
      "    accuracy                           0.84       755\n",
      "   macro avg       0.82      0.82      0.82       755\n",
      "weighted avg       0.84      0.84      0.84       755\n",
      "\n",
      "Backtesting for Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for Random Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for XGBoost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for SVM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for Naive Bayes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for Gradient Boosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for K-Nearest Neighbors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for Decision Tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for AdaBoost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for SGD Classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for LGBMClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Backtesting Result\n",
      "Normal Results and Returns Saved\n",
      "Working on merged_data_NVDA_from_2015-01-01_to_2025-03-01.csv\n",
      "Loading Data for NVDA, testing on number of lag 5, saving path is strategy_5\n",
      "\n",
      "Logistic Regression Performance:\n",
      "Accuracy: 0.8821\n",
      "Confusion Matrix:\n",
      "[[275  31]\n",
      " [ 58 391]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.90      0.86       306\n",
      "           1       0.93      0.87      0.90       449\n",
      "\n",
      "    accuracy                           0.88       755\n",
      "   macro avg       0.88      0.88      0.88       755\n",
      "weighted avg       0.89      0.88      0.88       755\n",
      "\n",
      "\n",
      "Random Forest Performance:\n",
      "Accuracy: 0.8940\n",
      "Confusion Matrix:\n",
      "[[268  38]\n",
      " [ 42 407]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.88      0.87       306\n",
      "           1       0.91      0.91      0.91       449\n",
      "\n",
      "    accuracy                           0.89       755\n",
      "   macro avg       0.89      0.89      0.89       755\n",
      "weighted avg       0.89      0.89      0.89       755\n",
      "\n",
      "\n",
      "XGBoost Performance:\n",
      "Accuracy: 0.8728\n",
      "Confusion Matrix:\n",
      "[[237  69]\n",
      " [ 27 422]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.77      0.83       306\n",
      "           1       0.86      0.94      0.90       449\n",
      "\n",
      "    accuracy                           0.87       755\n",
      "   macro avg       0.88      0.86      0.86       755\n",
      "weighted avg       0.87      0.87      0.87       755\n",
      "\n",
      "\n",
      "SVM Performance:\n",
      "Accuracy: 0.8808\n",
      "Confusion Matrix:\n",
      "[[281  25]\n",
      " [ 65 384]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.92      0.86       306\n",
      "           1       0.94      0.86      0.90       449\n",
      "\n",
      "    accuracy                           0.88       755\n",
      "   macro avg       0.88      0.89      0.88       755\n",
      "weighted avg       0.89      0.88      0.88       755\n",
      "\n",
      "\n",
      "Naive Bayes Performance:\n",
      "Accuracy: 0.8715\n",
      "Confusion Matrix:\n",
      "[[259  47]\n",
      " [ 50 399]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.85      0.84       306\n",
      "           1       0.89      0.89      0.89       449\n",
      "\n",
      "    accuracy                           0.87       755\n",
      "   macro avg       0.87      0.87      0.87       755\n",
      "weighted avg       0.87      0.87      0.87       755\n",
      "\n",
      "\n",
      "Gradient Boosting Performance:\n",
      "Accuracy: 0.8742\n",
      "Confusion Matrix:\n",
      "[[271  35]\n",
      " [ 60 389]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.89      0.85       306\n",
      "           1       0.92      0.87      0.89       449\n",
      "\n",
      "    accuracy                           0.87       755\n",
      "   macro avg       0.87      0.88      0.87       755\n",
      "weighted avg       0.88      0.87      0.87       755\n",
      "\n",
      "\n",
      "K-Nearest Neighbors Performance:\n",
      "Accuracy: 0.8424\n",
      "Confusion Matrix:\n",
      "[[256  50]\n",
      " [ 69 380]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.84      0.81       306\n",
      "           1       0.88      0.85      0.86       449\n",
      "\n",
      "    accuracy                           0.84       755\n",
      "   macro avg       0.84      0.84      0.84       755\n",
      "weighted avg       0.84      0.84      0.84       755\n",
      "\n",
      "\n",
      "Decision Tree Performance:\n",
      "Accuracy: 0.8450\n",
      "Confusion Matrix:\n",
      "[[238  68]\n",
      " [ 49 400]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.78      0.80       306\n",
      "           1       0.85      0.89      0.87       449\n",
      "\n",
      "    accuracy                           0.85       755\n",
      "   macro avg       0.84      0.83      0.84       755\n",
      "weighted avg       0.84      0.85      0.84       755\n",
      "\n",
      "\n",
      "AdaBoost Performance:\n",
      "Accuracy: 0.8940\n",
      "Confusion Matrix:\n",
      "[[262  44]\n",
      " [ 36 413]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.86      0.87       306\n",
      "           1       0.90      0.92      0.91       449\n",
      "\n",
      "    accuracy                           0.89       755\n",
      "   macro avg       0.89      0.89      0.89       755\n",
      "weighted avg       0.89      0.89      0.89       755\n",
      "\n",
      "\n",
      "SGD Classifier Performance:\n",
      "Accuracy: 0.7894\n",
      "Confusion Matrix:\n",
      "[[305   1]\n",
      " [158 291]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      1.00      0.79       306\n",
      "           1       1.00      0.65      0.79       449\n",
      "\n",
      "    accuracy                           0.79       755\n",
      "   macro avg       0.83      0.82      0.79       755\n",
      "weighted avg       0.86      0.79      0.79       755\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sachi\\Documents\\Researchcode\\research\\lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MLP Performance:\n",
      "Accuracy: 0.8623\n",
      "Confusion Matrix:\n",
      "[[267  39]\n",
      " [ 65 384]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.87      0.84       306\n",
      "           1       0.91      0.86      0.88       449\n",
      "\n",
      "    accuracy                           0.86       755\n",
      "   macro avg       0.86      0.86      0.86       755\n",
      "weighted avg       0.87      0.86      0.86       755\n",
      "\n",
      "[LightGBM] [Info] Number of positive: 1137, number of negative: 624\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000564 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6407\n",
      "[LightGBM] [Info] Number of data points in the train set: 1761, number of used features: 26\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.645656 -> initscore=0.599998\n",
      "[LightGBM] [Info] Start training from score 0.599998\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\n",
      "LGBMClassifier Performance:\n",
      "Accuracy: 0.8914\n",
      "Confusion Matrix:\n",
      "[[258  48]\n",
      " [ 34 415]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.84      0.86       306\n",
      "           1       0.90      0.92      0.91       449\n",
      "\n",
      "    accuracy                           0.89       755\n",
      "   macro avg       0.89      0.88      0.89       755\n",
      "weighted avg       0.89      0.89      0.89       755\n",
      "\n",
      "Backtesting for Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for Random Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for XGBoost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for SVM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for Naive Bayes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for Gradient Boosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for K-Nearest Neighbors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for Decision Tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for AdaBoost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for SGD Classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for LGBMClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Backtesting Result\n",
      "Normal Results and Returns Saved\n",
      "Working on merged_data_SPY_from_2015-01-01_to_2025-03-01.csv\n",
      "Loading Data for SPY, testing on number of lag 5, saving path is strategy_5\n",
      "\n",
      "Logistic Regression Performance:\n",
      "Accuracy: 0.8927\n",
      "Confusion Matrix:\n",
      "[[215  53]\n",
      " [ 28 459]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.80      0.84       268\n",
      "           1       0.90      0.94      0.92       487\n",
      "\n",
      "    accuracy                           0.89       755\n",
      "   macro avg       0.89      0.87      0.88       755\n",
      "weighted avg       0.89      0.89      0.89       755\n",
      "\n",
      "\n",
      "Random Forest Performance:\n",
      "Accuracy: 0.8887\n",
      "Confusion Matrix:\n",
      "[[244  24]\n",
      " [ 60 427]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.91      0.85       268\n",
      "           1       0.95      0.88      0.91       487\n",
      "\n",
      "    accuracy                           0.89       755\n",
      "   macro avg       0.87      0.89      0.88       755\n",
      "weighted avg       0.90      0.89      0.89       755\n",
      "\n",
      "\n",
      "XGBoost Performance:\n",
      "Accuracy: 0.9113\n",
      "Confusion Matrix:\n",
      "[[247  21]\n",
      " [ 46 441]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.92      0.88       268\n",
      "           1       0.95      0.91      0.93       487\n",
      "\n",
      "    accuracy                           0.91       755\n",
      "   macro avg       0.90      0.91      0.90       755\n",
      "weighted avg       0.91      0.91      0.91       755\n",
      "\n",
      "\n",
      "SVM Performance:\n",
      "Accuracy: 0.8887\n",
      "Confusion Matrix:\n",
      "[[208  60]\n",
      " [ 24 463]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.78      0.83       268\n",
      "           1       0.89      0.95      0.92       487\n",
      "\n",
      "    accuracy                           0.89       755\n",
      "   macro avg       0.89      0.86      0.87       755\n",
      "weighted avg       0.89      0.89      0.89       755\n",
      "\n",
      "\n",
      "Naive Bayes Performance:\n",
      "Accuracy: 0.8861\n",
      "Confusion Matrix:\n",
      "[[235  33]\n",
      " [ 53 434]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.88      0.85       268\n",
      "           1       0.93      0.89      0.91       487\n",
      "\n",
      "    accuracy                           0.89       755\n",
      "   macro avg       0.87      0.88      0.88       755\n",
      "weighted avg       0.89      0.89      0.89       755\n",
      "\n",
      "\n",
      "Gradient Boosting Performance:\n",
      "Accuracy: 0.8530\n",
      "Confusion Matrix:\n",
      "[[223  45]\n",
      " [ 66 421]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.83      0.80       268\n",
      "           1       0.90      0.86      0.88       487\n",
      "\n",
      "    accuracy                           0.85       755\n",
      "   macro avg       0.84      0.85      0.84       755\n",
      "weighted avg       0.86      0.85      0.85       755\n",
      "\n",
      "\n",
      "K-Nearest Neighbors Performance:\n",
      "Accuracy: 0.8000\n",
      "Confusion Matrix:\n",
      "[[186  82]\n",
      " [ 69 418]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.69      0.71       268\n",
      "           1       0.84      0.86      0.85       487\n",
      "\n",
      "    accuracy                           0.80       755\n",
      "   macro avg       0.78      0.78      0.78       755\n",
      "weighted avg       0.80      0.80      0.80       755\n",
      "\n",
      "\n",
      "Decision Tree Performance:\n",
      "Accuracy: 0.8291\n",
      "Confusion Matrix:\n",
      "[[224  44]\n",
      " [ 85 402]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.84      0.78       268\n",
      "           1       0.90      0.83      0.86       487\n",
      "\n",
      "    accuracy                           0.83       755\n",
      "   macro avg       0.81      0.83      0.82       755\n",
      "weighted avg       0.84      0.83      0.83       755\n",
      "\n",
      "\n",
      "AdaBoost Performance:\n",
      "Accuracy: 0.8795\n",
      "Confusion Matrix:\n",
      "[[250  18]\n",
      " [ 73 414]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.93      0.85       268\n",
      "           1       0.96      0.85      0.90       487\n",
      "\n",
      "    accuracy                           0.88       755\n",
      "   macro avg       0.87      0.89      0.87       755\n",
      "weighted avg       0.89      0.88      0.88       755\n",
      "\n",
      "\n",
      "SGD Classifier Performance:\n",
      "Accuracy: 0.8901\n",
      "Confusion Matrix:\n",
      "[[212  56]\n",
      " [ 27 460]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.79      0.84       268\n",
      "           1       0.89      0.94      0.92       487\n",
      "\n",
      "    accuracy                           0.89       755\n",
      "   macro avg       0.89      0.87      0.88       755\n",
      "weighted avg       0.89      0.89      0.89       755\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sachi\\Documents\\Researchcode\\research\\lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MLP Performance:\n",
      "Accuracy: 0.7947\n",
      "Confusion Matrix:\n",
      "[[129 139]\n",
      " [ 16 471]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.48      0.62       268\n",
      "           1       0.77      0.97      0.86       487\n",
      "\n",
      "    accuracy                           0.79       755\n",
      "   macro avg       0.83      0.72      0.74       755\n",
      "weighted avg       0.81      0.79      0.78       755\n",
      "\n",
      "[LightGBM] [Info] Number of positive: 1123, number of negative: 638\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000537 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6446\n",
      "[LightGBM] [Info] Number of data points in the train set: 1761, number of used features: 26\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.637706 -> initscore=0.565421\n",
      "[LightGBM] [Info] Start training from score 0.565421\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\n",
      "LGBMClassifier Performance:\n",
      "Accuracy: 0.8464\n",
      "Confusion Matrix:\n",
      "[[224  44]\n",
      " [ 72 415]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.84      0.79       268\n",
      "           1       0.90      0.85      0.88       487\n",
      "\n",
      "    accuracy                           0.85       755\n",
      "   macro avg       0.83      0.84      0.84       755\n",
      "weighted avg       0.85      0.85      0.85       755\n",
      "\n",
      "Backtesting for Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for Random Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for XGBoost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for SVM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for Naive Bayes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for Gradient Boosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for K-Nearest Neighbors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for Decision Tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for AdaBoost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for SGD Classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for LGBMClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Backtesting Result\n",
      "Normal Results and Returns Saved\n",
      "Working on merged_data_TSLA_from_2015-01-01_to_2025-03-01.csv\n",
      "Loading Data for TSLA, testing on number of lag 5, saving path is strategy_5\n",
      "\n",
      "Logistic Regression Performance:\n",
      "Accuracy: 0.8411\n",
      "Confusion Matrix:\n",
      "[[368  62]\n",
      " [ 58 267]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86       430\n",
      "           1       0.81      0.82      0.82       325\n",
      "\n",
      "    accuracy                           0.84       755\n",
      "   macro avg       0.84      0.84      0.84       755\n",
      "weighted avg       0.84      0.84      0.84       755\n",
      "\n",
      "\n",
      "Random Forest Performance:\n",
      "Accuracy: 0.8861\n",
      "Confusion Matrix:\n",
      "[[376  54]\n",
      " [ 32 293]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.87      0.90       430\n",
      "           1       0.84      0.90      0.87       325\n",
      "\n",
      "    accuracy                           0.89       755\n",
      "   macro avg       0.88      0.89      0.88       755\n",
      "weighted avg       0.89      0.89      0.89       755\n",
      "\n",
      "\n",
      "XGBoost Performance:\n",
      "Accuracy: 0.8702\n",
      "Confusion Matrix:\n",
      "[[376  54]\n",
      " [ 44 281]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.87      0.88       430\n",
      "           1       0.84      0.86      0.85       325\n",
      "\n",
      "    accuracy                           0.87       755\n",
      "   macro avg       0.87      0.87      0.87       755\n",
      "weighted avg       0.87      0.87      0.87       755\n",
      "\n",
      "\n",
      "SVM Performance:\n",
      "Accuracy: 0.8358\n",
      "Confusion Matrix:\n",
      "[[367  63]\n",
      " [ 61 264]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.85      0.86       430\n",
      "           1       0.81      0.81      0.81       325\n",
      "\n",
      "    accuracy                           0.84       755\n",
      "   macro avg       0.83      0.83      0.83       755\n",
      "weighted avg       0.84      0.84      0.84       755\n",
      "\n",
      "\n",
      "Naive Bayes Performance:\n",
      "Accuracy: 0.8146\n",
      "Confusion Matrix:\n",
      "[[336  94]\n",
      " [ 46 279]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.78      0.83       430\n",
      "           1       0.75      0.86      0.80       325\n",
      "\n",
      "    accuracy                           0.81       755\n",
      "   macro avg       0.81      0.82      0.81       755\n",
      "weighted avg       0.82      0.81      0.82       755\n",
      "\n",
      "\n",
      "Gradient Boosting Performance:\n",
      "Accuracy: 0.8755\n",
      "Confusion Matrix:\n",
      "[[373  57]\n",
      " [ 37 288]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.87      0.89       430\n",
      "           1       0.83      0.89      0.86       325\n",
      "\n",
      "    accuracy                           0.88       755\n",
      "   macro avg       0.87      0.88      0.87       755\n",
      "weighted avg       0.88      0.88      0.88       755\n",
      "\n",
      "\n",
      "K-Nearest Neighbors Performance:\n",
      "Accuracy: 0.8265\n",
      "Confusion Matrix:\n",
      "[[344  86]\n",
      " [ 45 280]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.80      0.84       430\n",
      "           1       0.77      0.86      0.81       325\n",
      "\n",
      "    accuracy                           0.83       755\n",
      "   macro avg       0.82      0.83      0.83       755\n",
      "weighted avg       0.83      0.83      0.83       755\n",
      "\n",
      "\n",
      "Decision Tree Performance:\n",
      "Accuracy: 0.8874\n",
      "Confusion Matrix:\n",
      "[[385  45]\n",
      " [ 40 285]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.90       430\n",
      "           1       0.86      0.88      0.87       325\n",
      "\n",
      "    accuracy                           0.89       755\n",
      "   macro avg       0.88      0.89      0.89       755\n",
      "weighted avg       0.89      0.89      0.89       755\n",
      "\n",
      "\n",
      "AdaBoost Performance:\n",
      "Accuracy: 0.8768\n",
      "Confusion Matrix:\n",
      "[[374  56]\n",
      " [ 37 288]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.87      0.89       430\n",
      "           1       0.84      0.89      0.86       325\n",
      "\n",
      "    accuracy                           0.88       755\n",
      "   macro avg       0.87      0.88      0.88       755\n",
      "weighted avg       0.88      0.88      0.88       755\n",
      "\n",
      "\n",
      "SGD Classifier Performance:\n",
      "Accuracy: 0.8530\n",
      "Confusion Matrix:\n",
      "[[398  32]\n",
      " [ 79 246]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88       430\n",
      "           1       0.88      0.76      0.82       325\n",
      "\n",
      "    accuracy                           0.85       755\n",
      "   macro avg       0.86      0.84      0.85       755\n",
      "weighted avg       0.86      0.85      0.85       755\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sachi\\Documents\\Researchcode\\research\\lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MLP Performance:\n",
      "Accuracy: 0.8238\n",
      "Confusion Matrix:\n",
      "[[379  51]\n",
      " [ 82 243]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.88      0.85       430\n",
      "           1       0.83      0.75      0.79       325\n",
      "\n",
      "    accuracy                           0.82       755\n",
      "   macro avg       0.82      0.81      0.82       755\n",
      "weighted avg       0.82      0.82      0.82       755\n",
      "\n",
      "[LightGBM] [Info] Number of positive: 940, number of negative: 821\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000631 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6443\n",
      "[LightGBM] [Info] Number of data points in the train set: 1761, number of used features: 26\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.533788 -> initscore=0.135357\n",
      "[LightGBM] [Info] Start training from score 0.135357\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\n",
      "LGBMClassifier Performance:\n",
      "Accuracy: 0.8914\n",
      "Confusion Matrix:\n",
      "[[377  53]\n",
      " [ 29 296]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.90       430\n",
      "           1       0.85      0.91      0.88       325\n",
      "\n",
      "    accuracy                           0.89       755\n",
      "   macro avg       0.89      0.89      0.89       755\n",
      "weighted avg       0.89      0.89      0.89       755\n",
      "\n",
      "Backtesting for Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for Random Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for XGBoost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for SVM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for Naive Bayes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for Gradient Boosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for K-Nearest Neighbors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for Decision Tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for AdaBoost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for SGD Classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for LGBMClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Backtesting Result\n",
      "Normal Results and Returns Saved\n"
     ]
    }
   ],
   "source": [
    "all_dfs = []  # Create a list to store all DataFrames\n",
    "for lag in range(5,6):\n",
    "    combined_collector, ticker = normal_run(lag)\n",
    "    all_dfs.append(combined_collector)\n",
    "df = pd.concat(combined_collector.values(),axis=0, keys=list(combined_collector.keys()))\n",
    "df.to_csv(f'master_combined_df_{lag}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['AAPL', 'AMD', 'AMZN', 'GOOGL', 'META', 'MSFT', 'NFLX', 'NVDA', 'SPY', 'TSLA'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_dfs[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AAPL', 'AMD', 'AMZN', 'GOOGL', 'META', 'MSFT', 'NFLX', 'NVDA', 'SPY', 'TSLA']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(combined_collector.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('master_combined_df_5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Exposure Time [%]</th>\n",
       "      <th>Equity Final [$]</th>\n",
       "      <th>Equity Peak [$]</th>\n",
       "      <th>Return [%]</th>\n",
       "      <th>Buy &amp; Hold Return [%]</th>\n",
       "      <th>Return (Ann.) [%]</th>\n",
       "      <th>Volatility (Ann.) [%]</th>\n",
       "      <th>CAGR [%]</th>\n",
       "      <th>Sharpe Ratio</th>\n",
       "      <th>Sortino Ratio</th>\n",
       "      <th>Calmar Ratio</th>\n",
       "      <th>Alpha [%]</th>\n",
       "      <th>Beta</th>\n",
       "      <th>Max. Drawdown [%]</th>\n",
       "      <th>Avg. Drawdown [%]</th>\n",
       "      <th>Max. Drawdown Duration</th>\n",
       "      <th>Avg. Drawdown Duration</th>\n",
       "      <th># Trades</th>\n",
       "      <th>Win Rate [%]</th>\n",
       "      <th>Best Trade [%]</th>\n",
       "      <th>Worst Trade [%]</th>\n",
       "      <th>Avg. Trade [%]</th>\n",
       "      <th>Max. Trade Duration</th>\n",
       "      <th>Avg. Trade Duration</th>\n",
       "      <th>Profit Factor</th>\n",
       "      <th>Expectancy [%]</th>\n",
       "      <th>SQN</th>\n",
       "      <th>Kelly Criterion</th>\n",
       "      <th>_strategy</th>\n",
       "      <th>_equity_curve</th>\n",
       "      <th>_trades</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>0</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.859603</td>\n",
       "      <td>[[270  91]\\n [ 15 379]]</td>\n",
       "      <td>2022-02-24</td>\n",
       "      <td>2025-02-27</td>\n",
       "      <td>1099 days</td>\n",
       "      <td>64.105960</td>\n",
       "      <td>12137.119415</td>\n",
       "      <td>14718.868225</td>\n",
       "      <td>21.371194</td>\n",
       "      <td>45.815408</td>\n",
       "      <td>6.678200</td>\n",
       "      <td>19.377001</td>\n",
       "      <td>4.541243</td>\n",
       "      <td>0.344646</td>\n",
       "      <td>0.536860</td>\n",
       "      <td>0.294507</td>\n",
       "      <td>1.035359</td>\n",
       "      <td>0.443865</td>\n",
       "      <td>-22.675884</td>\n",
       "      <td>-5.422704</td>\n",
       "      <td>316 days</td>\n",
       "      <td>70 days</td>\n",
       "      <td>25</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>18.444586</td>\n",
       "      <td>-7.227740</td>\n",
       "      <td>0.782199</td>\n",
       "      <td>154 days</td>\n",
       "      <td>27 days</td>\n",
       "      <td>1.572781</td>\n",
       "      <td>0.971453</td>\n",
       "      <td>0.619699</td>\n",
       "      <td>0.109951</td>\n",
       "      <td>MyStrategy</td>\n",
       "      <td>Equity  DrawdownPct Drawdown...</td>\n",
       "      <td>Size  EntryBar  ExitBar  EntryPrice   Exit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>1</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>[[261 100]\\n [ 20 374]]</td>\n",
       "      <td>2022-02-24</td>\n",
       "      <td>2025-02-27</td>\n",
       "      <td>1099 days</td>\n",
       "      <td>65.430464</td>\n",
       "      <td>13169.351395</td>\n",
       "      <td>13708.351562</td>\n",
       "      <td>31.693514</td>\n",
       "      <td>45.815408</td>\n",
       "      <td>9.624489</td>\n",
       "      <td>20.471350</td>\n",
       "      <td>6.516292</td>\n",
       "      <td>0.470144</td>\n",
       "      <td>0.759055</td>\n",
       "      <td>0.376969</td>\n",
       "      <td>10.608332</td>\n",
       "      <td>0.460220</td>\n",
       "      <td>-25.531269</td>\n",
       "      <td>-5.108571</td>\n",
       "      <td>664 days</td>\n",
       "      <td>81 days</td>\n",
       "      <td>33</td>\n",
       "      <td>27.272727</td>\n",
       "      <td>28.737927</td>\n",
       "      <td>-7.227740</td>\n",
       "      <td>0.724516</td>\n",
       "      <td>154 days</td>\n",
       "      <td>21 days</td>\n",
       "      <td>1.580424</td>\n",
       "      <td>0.947442</td>\n",
       "      <td>0.666842</td>\n",
       "      <td>0.087513</td>\n",
       "      <td>MyStrategy</td>\n",
       "      <td>Equity  DrawdownPct Drawdown...</td>\n",
       "      <td>Size  EntryBar  ExitBar  EntryPrice   Exit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.882119</td>\n",
       "      <td>[[301  60]\\n [ 29 365]]</td>\n",
       "      <td>2022-02-24</td>\n",
       "      <td>2025-02-27</td>\n",
       "      <td>1099 days</td>\n",
       "      <td>57.483444</td>\n",
       "      <td>11478.308929</td>\n",
       "      <td>14018.039291</td>\n",
       "      <td>14.783089</td>\n",
       "      <td>45.815408</td>\n",
       "      <td>4.709416</td>\n",
       "      <td>17.832974</td>\n",
       "      <td>3.211946</td>\n",
       "      <td>0.264085</td>\n",
       "      <td>0.398605</td>\n",
       "      <td>0.187299</td>\n",
       "      <td>-3.250551</td>\n",
       "      <td>0.393615</td>\n",
       "      <td>-25.143807</td>\n",
       "      <td>-4.958430</td>\n",
       "      <td>322 days</td>\n",
       "      <td>62 days</td>\n",
       "      <td>19</td>\n",
       "      <td>36.842105</td>\n",
       "      <td>31.333133</td>\n",
       "      <td>-7.227740</td>\n",
       "      <td>0.820111</td>\n",
       "      <td>202 days</td>\n",
       "      <td>33 days</td>\n",
       "      <td>1.542882</td>\n",
       "      <td>1.157159</td>\n",
       "      <td>0.449230</td>\n",
       "      <td>0.101572</td>\n",
       "      <td>MyStrategy</td>\n",
       "      <td>Equity  DrawdownPct Drawdown...</td>\n",
       "      <td>Size  EntryBar  ExitBar  EntryPrice   Exit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>3</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.862252</td>\n",
       "      <td>[[277  84]\\n [ 20 374]]</td>\n",
       "      <td>2022-02-24</td>\n",
       "      <td>2025-02-27</td>\n",
       "      <td>1099 days</td>\n",
       "      <td>62.251656</td>\n",
       "      <td>13620.879593</td>\n",
       "      <td>16925.867569</td>\n",
       "      <td>36.208796</td>\n",
       "      <td>45.815408</td>\n",
       "      <td>10.864960</td>\n",
       "      <td>20.021312</td>\n",
       "      <td>7.342859</td>\n",
       "      <td>0.542670</td>\n",
       "      <td>0.895741</td>\n",
       "      <td>0.519091</td>\n",
       "      <td>16.214559</td>\n",
       "      <td>0.436409</td>\n",
       "      <td>-20.930749</td>\n",
       "      <td>-3.612226</td>\n",
       "      <td>295 days</td>\n",
       "      <td>42 days</td>\n",
       "      <td>23</td>\n",
       "      <td>34.782609</td>\n",
       "      <td>34.631879</td>\n",
       "      <td>-7.227740</td>\n",
       "      <td>1.342827</td>\n",
       "      <td>199 days</td>\n",
       "      <td>29 days</td>\n",
       "      <td>1.982104</td>\n",
       "      <td>1.680972</td>\n",
       "      <td>0.791937</td>\n",
       "      <td>0.147910</td>\n",
       "      <td>MyStrategy</td>\n",
       "      <td>Equity  DrawdownPct Drawdown...</td>\n",
       "      <td>Size  EntryBar  ExitBar  EntryPrice   Exit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>4</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.867550</td>\n",
       "      <td>[[277  84]\\n [ 16 378]]</td>\n",
       "      <td>2022-02-24</td>\n",
       "      <td>2025-02-27</td>\n",
       "      <td>1099 days</td>\n",
       "      <td>62.119205</td>\n",
       "      <td>11225.919205</td>\n",
       "      <td>13555.259567</td>\n",
       "      <td>12.259192</td>\n",
       "      <td>45.815408</td>\n",
       "      <td>3.935237</td>\n",
       "      <td>19.580896</td>\n",
       "      <td>2.687091</td>\n",
       "      <td>0.200973</td>\n",
       "      <td>0.303097</td>\n",
       "      <td>0.189537</td>\n",
       "      <td>-9.285530</td>\n",
       "      <td>0.470251</td>\n",
       "      <td>-20.762398</td>\n",
       "      <td>-4.879187</td>\n",
       "      <td>345 days</td>\n",
       "      <td>53 days</td>\n",
       "      <td>18</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>36.097860</td>\n",
       "      <td>-10.119737</td>\n",
       "      <td>0.639028</td>\n",
       "      <td>207 days</td>\n",
       "      <td>37 days</td>\n",
       "      <td>1.414197</td>\n",
       "      <td>1.075246</td>\n",
       "      <td>0.297931</td>\n",
       "      <td>0.064827</td>\n",
       "      <td>MyStrategy</td>\n",
       "      <td>Equity  DrawdownPct Drawdown...</td>\n",
       "      <td>Size  EntryBar  ExitBar  EntryPrice   Exit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>7</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.887417</td>\n",
       "      <td>[[385  45]\\n [ 40 285]]</td>\n",
       "      <td>2022-02-24</td>\n",
       "      <td>2025-02-27</td>\n",
       "      <td>1099 days</td>\n",
       "      <td>46.357616</td>\n",
       "      <td>26828.085953</td>\n",
       "      <td>28160.187088</td>\n",
       "      <td>168.280860</td>\n",
       "      <td>5.629584</td>\n",
       "      <td>39.012051</td>\n",
       "      <td>53.978656</td>\n",
       "      <td>25.393592</td>\n",
       "      <td>0.722731</td>\n",
       "      <td>1.600172</td>\n",
       "      <td>1.073634</td>\n",
       "      <td>166.105630</td>\n",
       "      <td>0.386393</td>\n",
       "      <td>-36.336442</td>\n",
       "      <td>-8.962031</td>\n",
       "      <td>482 days</td>\n",
       "      <td>70 days</td>\n",
       "      <td>20</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>64.056085</td>\n",
       "      <td>-11.036302</td>\n",
       "      <td>5.087299</td>\n",
       "      <td>86 days</td>\n",
       "      <td>25 days</td>\n",
       "      <td>3.776273</td>\n",
       "      <td>6.687328</td>\n",
       "      <td>1.254875</td>\n",
       "      <td>0.270756</td>\n",
       "      <td>MyStrategy</td>\n",
       "      <td>Equity  DrawdownPct Drawdown...</td>\n",
       "      <td>Size  EntryBar  ExitBar  EntryPrice   Exit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>8</td>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.876821</td>\n",
       "      <td>[[374  56]\\n [ 37 288]]</td>\n",
       "      <td>2022-02-24</td>\n",
       "      <td>2025-02-27</td>\n",
       "      <td>1099 days</td>\n",
       "      <td>48.874172</td>\n",
       "      <td>11008.450775</td>\n",
       "      <td>14887.489380</td>\n",
       "      <td>10.084508</td>\n",
       "      <td>5.629584</td>\n",
       "      <td>3.258820</td>\n",
       "      <td>40.941429</td>\n",
       "      <td>2.227512</td>\n",
       "      <td>0.079597</td>\n",
       "      <td>0.124330</td>\n",
       "      <td>0.063679</td>\n",
       "      <td>7.820838</td>\n",
       "      <td>0.402103</td>\n",
       "      <td>-51.175793</td>\n",
       "      <td>-16.677032</td>\n",
       "      <td>518 days</td>\n",
       "      <td>118 days</td>\n",
       "      <td>25</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>45.311521</td>\n",
       "      <td>-15.120215</td>\n",
       "      <td>0.373339</td>\n",
       "      <td>73 days</td>\n",
       "      <td>21 days</td>\n",
       "      <td>1.285434</td>\n",
       "      <td>1.257144</td>\n",
       "      <td>0.151993</td>\n",
       "      <td>0.029563</td>\n",
       "      <td>MyStrategy</td>\n",
       "      <td>Equity  DrawdownPct Drawdown...</td>\n",
       "      <td>Size  EntryBar  ExitBar  EntryPrice   Exit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>9</td>\n",
       "      <td>SGD Classifier</td>\n",
       "      <td>0.852980</td>\n",
       "      <td>[[398  32]\\n [ 79 246]]</td>\n",
       "      <td>2022-02-24</td>\n",
       "      <td>2025-02-27</td>\n",
       "      <td>1099 days</td>\n",
       "      <td>40.927152</td>\n",
       "      <td>18695.022369</td>\n",
       "      <td>21813.924789</td>\n",
       "      <td>86.950224</td>\n",
       "      <td>5.629584</td>\n",
       "      <td>23.223998</td>\n",
       "      <td>43.787642</td>\n",
       "      <td>15.426784</td>\n",
       "      <td>0.530378</td>\n",
       "      <td>1.012579</td>\n",
       "      <td>0.525730</td>\n",
       "      <td>85.136378</td>\n",
       "      <td>0.322199</td>\n",
       "      <td>-44.174763</td>\n",
       "      <td>-10.929480</td>\n",
       "      <td>590 days</td>\n",
       "      <td>87 days</td>\n",
       "      <td>31</td>\n",
       "      <td>41.935484</td>\n",
       "      <td>39.616579</td>\n",
       "      <td>-14.511042</td>\n",
       "      <td>2.056302</td>\n",
       "      <td>42 days</td>\n",
       "      <td>14 days</td>\n",
       "      <td>1.963487</td>\n",
       "      <td>2.745109</td>\n",
       "      <td>0.905445</td>\n",
       "      <td>0.164256</td>\n",
       "      <td>MyStrategy</td>\n",
       "      <td>Equity  DrawdownPct Drawdown...</td>\n",
       "      <td>Size  EntryBar  ExitBar  EntryPrice   Exit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>10</td>\n",
       "      <td>MLP</td>\n",
       "      <td>0.823841</td>\n",
       "      <td>[[379  51]\\n [ 82 243]]</td>\n",
       "      <td>2022-02-24</td>\n",
       "      <td>2025-02-27</td>\n",
       "      <td>1099 days</td>\n",
       "      <td>42.913907</td>\n",
       "      <td>13457.272873</td>\n",
       "      <td>17942.492996</td>\n",
       "      <td>34.572729</td>\n",
       "      <td>5.629584</td>\n",
       "      <td>10.418698</td>\n",
       "      <td>39.406034</td>\n",
       "      <td>7.045834</td>\n",
       "      <td>0.264393</td>\n",
       "      <td>0.453198</td>\n",
       "      <td>0.207478</td>\n",
       "      <td>32.713517</td>\n",
       "      <td>0.330257</td>\n",
       "      <td>-50.215890</td>\n",
       "      <td>-14.042097</td>\n",
       "      <td>512 days</td>\n",
       "      <td>106 days</td>\n",
       "      <td>30</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>37.411191</td>\n",
       "      <td>-14.434636</td>\n",
       "      <td>0.985784</td>\n",
       "      <td>37 days</td>\n",
       "      <td>14 days</td>\n",
       "      <td>1.423032</td>\n",
       "      <td>1.864075</td>\n",
       "      <td>0.429292</td>\n",
       "      <td>0.055025</td>\n",
       "      <td>MyStrategy</td>\n",
       "      <td>Equity  DrawdownPct Drawdown...</td>\n",
       "      <td>Size  EntryBar  ExitBar  EntryPrice   Exit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>11</td>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.891391</td>\n",
       "      <td>[[377  53]\\n [ 29 296]]</td>\n",
       "      <td>2022-02-24</td>\n",
       "      <td>2025-02-27</td>\n",
       "      <td>1099 days</td>\n",
       "      <td>49.006623</td>\n",
       "      <td>24392.040710</td>\n",
       "      <td>28900.789124</td>\n",
       "      <td>143.920407</td>\n",
       "      <td>5.629584</td>\n",
       "      <td>34.664674</td>\n",
       "      <td>54.234654</td>\n",
       "      <td>22.686210</td>\n",
       "      <td>0.639161</td>\n",
       "      <td>1.372513</td>\n",
       "      <td>0.934452</td>\n",
       "      <td>141.604062</td>\n",
       "      <td>0.411459</td>\n",
       "      <td>-37.096251</td>\n",
       "      <td>-10.236035</td>\n",
       "      <td>482 days</td>\n",
       "      <td>70 days</td>\n",
       "      <td>21</td>\n",
       "      <td>28.571429</td>\n",
       "      <td>63.821717</td>\n",
       "      <td>-11.036302</td>\n",
       "      <td>4.360772</td>\n",
       "      <td>66 days</td>\n",
       "      <td>25 days</td>\n",
       "      <td>3.098732</td>\n",
       "      <td>5.868940</td>\n",
       "      <td>1.141884</td>\n",
       "      <td>0.177048</td>\n",
       "      <td>MyStrategy</td>\n",
       "      <td>Equity  DrawdownPct DrawdownD...</td>\n",
       "      <td>Size  EntryBar  ExitBar  EntryPrice   Exit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows  39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  Unnamed: 1                Model  Accuracy  \\\n",
       "0         AAPL           0  Logistic Regression  0.859603   \n",
       "1         AAPL           1        Random Forest  0.841060   \n",
       "2         AAPL           2              XGBoost  0.882119   \n",
       "3         AAPL           3                  SVM  0.862252   \n",
       "4         AAPL           4          Naive Bayes  0.867550   \n",
       "..         ...         ...                  ...       ...   \n",
       "115       TSLA           7        Decision Tree  0.887417   \n",
       "116       TSLA           8             AdaBoost  0.876821   \n",
       "117       TSLA           9       SGD Classifier  0.852980   \n",
       "118       TSLA          10                  MLP  0.823841   \n",
       "119       TSLA          11       LGBMClassifier  0.891391   \n",
       "\n",
       "            Confusion Matrix       Start         End   Duration  \\\n",
       "0    [[270  91]\\n [ 15 379]]  2022-02-24  2025-02-27  1099 days   \n",
       "1    [[261 100]\\n [ 20 374]]  2022-02-24  2025-02-27  1099 days   \n",
       "2    [[301  60]\\n [ 29 365]]  2022-02-24  2025-02-27  1099 days   \n",
       "3    [[277  84]\\n [ 20 374]]  2022-02-24  2025-02-27  1099 days   \n",
       "4    [[277  84]\\n [ 16 378]]  2022-02-24  2025-02-27  1099 days   \n",
       "..                       ...         ...         ...        ...   \n",
       "115  [[385  45]\\n [ 40 285]]  2022-02-24  2025-02-27  1099 days   \n",
       "116  [[374  56]\\n [ 37 288]]  2022-02-24  2025-02-27  1099 days   \n",
       "117  [[398  32]\\n [ 79 246]]  2022-02-24  2025-02-27  1099 days   \n",
       "118  [[379  51]\\n [ 82 243]]  2022-02-24  2025-02-27  1099 days   \n",
       "119  [[377  53]\\n [ 29 296]]  2022-02-24  2025-02-27  1099 days   \n",
       "\n",
       "     Exposure Time [%]  Equity Final [$]  Equity Peak [$]  Return [%]  \\\n",
       "0            64.105960      12137.119415     14718.868225   21.371194   \n",
       "1            65.430464      13169.351395     13708.351562   31.693514   \n",
       "2            57.483444      11478.308929     14018.039291   14.783089   \n",
       "3            62.251656      13620.879593     16925.867569   36.208796   \n",
       "4            62.119205      11225.919205     13555.259567   12.259192   \n",
       "..                 ...               ...              ...         ...   \n",
       "115          46.357616      26828.085953     28160.187088  168.280860   \n",
       "116          48.874172      11008.450775     14887.489380   10.084508   \n",
       "117          40.927152      18695.022369     21813.924789   86.950224   \n",
       "118          42.913907      13457.272873     17942.492996   34.572729   \n",
       "119          49.006623      24392.040710     28900.789124  143.920407   \n",
       "\n",
       "     Buy & Hold Return [%]  Return (Ann.) [%]  Volatility (Ann.) [%]  \\\n",
       "0                45.815408           6.678200              19.377001   \n",
       "1                45.815408           9.624489              20.471350   \n",
       "2                45.815408           4.709416              17.832974   \n",
       "3                45.815408          10.864960              20.021312   \n",
       "4                45.815408           3.935237              19.580896   \n",
       "..                     ...                ...                    ...   \n",
       "115               5.629584          39.012051              53.978656   \n",
       "116               5.629584           3.258820              40.941429   \n",
       "117               5.629584          23.223998              43.787642   \n",
       "118               5.629584          10.418698              39.406034   \n",
       "119               5.629584          34.664674              54.234654   \n",
       "\n",
       "      CAGR [%]  Sharpe Ratio  Sortino Ratio  Calmar Ratio   Alpha [%]  \\\n",
       "0     4.541243      0.344646       0.536860      0.294507    1.035359   \n",
       "1     6.516292      0.470144       0.759055      0.376969   10.608332   \n",
       "2     3.211946      0.264085       0.398605      0.187299   -3.250551   \n",
       "3     7.342859      0.542670       0.895741      0.519091   16.214559   \n",
       "4     2.687091      0.200973       0.303097      0.189537   -9.285530   \n",
       "..         ...           ...            ...           ...         ...   \n",
       "115  25.393592      0.722731       1.600172      1.073634  166.105630   \n",
       "116   2.227512      0.079597       0.124330      0.063679    7.820838   \n",
       "117  15.426784      0.530378       1.012579      0.525730   85.136378   \n",
       "118   7.045834      0.264393       0.453198      0.207478   32.713517   \n",
       "119  22.686210      0.639161       1.372513      0.934452  141.604062   \n",
       "\n",
       "         Beta  Max. Drawdown [%]  Avg. Drawdown [%] Max. Drawdown Duration  \\\n",
       "0    0.443865         -22.675884          -5.422704               316 days   \n",
       "1    0.460220         -25.531269          -5.108571               664 days   \n",
       "2    0.393615         -25.143807          -4.958430               322 days   \n",
       "3    0.436409         -20.930749          -3.612226               295 days   \n",
       "4    0.470251         -20.762398          -4.879187               345 days   \n",
       "..        ...                ...                ...                    ...   \n",
       "115  0.386393         -36.336442          -8.962031               482 days   \n",
       "116  0.402103         -51.175793         -16.677032               518 days   \n",
       "117  0.322199         -44.174763         -10.929480               590 days   \n",
       "118  0.330257         -50.215890         -14.042097               512 days   \n",
       "119  0.411459         -37.096251         -10.236035               482 days   \n",
       "\n",
       "    Avg. Drawdown Duration  # Trades  Win Rate [%]  Best Trade [%]  \\\n",
       "0                  70 days        25     36.000000       18.444586   \n",
       "1                  81 days        33     27.272727       28.737927   \n",
       "2                  62 days        19     36.842105       31.333133   \n",
       "3                  42 days        23     34.782609       34.631879   \n",
       "4                  53 days        18     33.333333       36.097860   \n",
       "..                     ...       ...           ...             ...   \n",
       "115                70 days        20     40.000000       64.056085   \n",
       "116               118 days        25     36.000000       45.311521   \n",
       "117                87 days        31     41.935484       39.616579   \n",
       "118               106 days        30     30.000000       37.411191   \n",
       "119                70 days        21     28.571429       63.821717   \n",
       "\n",
       "     Worst Trade [%]  Avg. Trade [%] Max. Trade Duration Avg. Trade Duration  \\\n",
       "0          -7.227740        0.782199            154 days             27 days   \n",
       "1          -7.227740        0.724516            154 days             21 days   \n",
       "2          -7.227740        0.820111            202 days             33 days   \n",
       "3          -7.227740        1.342827            199 days             29 days   \n",
       "4         -10.119737        0.639028            207 days             37 days   \n",
       "..               ...             ...                 ...                 ...   \n",
       "115       -11.036302        5.087299             86 days             25 days   \n",
       "116       -15.120215        0.373339             73 days             21 days   \n",
       "117       -14.511042        2.056302             42 days             14 days   \n",
       "118       -14.434636        0.985784             37 days             14 days   \n",
       "119       -11.036302        4.360772             66 days             25 days   \n",
       "\n",
       "     Profit Factor  Expectancy [%]       SQN  Kelly Criterion   _strategy  \\\n",
       "0         1.572781        0.971453  0.619699         0.109951  MyStrategy   \n",
       "1         1.580424        0.947442  0.666842         0.087513  MyStrategy   \n",
       "2         1.542882        1.157159  0.449230         0.101572  MyStrategy   \n",
       "3         1.982104        1.680972  0.791937         0.147910  MyStrategy   \n",
       "4         1.414197        1.075246  0.297931         0.064827  MyStrategy   \n",
       "..             ...             ...       ...              ...         ...   \n",
       "115       3.776273        6.687328  1.254875         0.270756  MyStrategy   \n",
       "116       1.285434        1.257144  0.151993         0.029563  MyStrategy   \n",
       "117       1.963487        2.745109  0.905445         0.164256  MyStrategy   \n",
       "118       1.423032        1.864075  0.429292         0.055025  MyStrategy   \n",
       "119       3.098732        5.868940  1.141884         0.177048  MyStrategy   \n",
       "\n",
       "                                         _equity_curve  \\\n",
       "0                      Equity  DrawdownPct Drawdown...   \n",
       "1                      Equity  DrawdownPct Drawdown...   \n",
       "2                      Equity  DrawdownPct Drawdown...   \n",
       "3                      Equity  DrawdownPct Drawdown...   \n",
       "4                      Equity  DrawdownPct Drawdown...   \n",
       "..                                                 ...   \n",
       "115                    Equity  DrawdownPct Drawdown...   \n",
       "116                    Equity  DrawdownPct Drawdown...   \n",
       "117                    Equity  DrawdownPct Drawdown...   \n",
       "118                    Equity  DrawdownPct Drawdown...   \n",
       "119                   Equity  DrawdownPct DrawdownD...   \n",
       "\n",
       "                                               _trades  \n",
       "0        Size  EntryBar  ExitBar  EntryPrice   Exit...  \n",
       "1        Size  EntryBar  ExitBar  EntryPrice   Exit...  \n",
       "2        Size  EntryBar  ExitBar  EntryPrice   Exit...  \n",
       "3        Size  EntryBar  ExitBar  EntryPrice   Exit...  \n",
       "4        Size  EntryBar  ExitBar  EntryPrice   Exit...  \n",
       "..                                                 ...  \n",
       "115      Size  EntryBar  ExitBar  EntryPrice   Exit...  \n",
       "116      Size  EntryBar  ExitBar  EntryPrice   Exit...  \n",
       "117      Size  EntryBar  ExitBar  EntryPrice   Exit...  \n",
       "118      Size  EntryBar  ExitBar  EntryPrice   Exit...  \n",
       "119      Size  EntryBar  ExitBar  EntryPrice   Exit...  \n",
       "\n",
       "[120 rows x 39 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
